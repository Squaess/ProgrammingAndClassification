{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "from nltk.metrics import edit_distance\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proccess(text):\n",
    "    return set(\n",
    "        [w.lower() for w in text if len(w) <= 7]\n",
    "    )\n",
    "    \n",
    "pro = [list(proccess(t)) for t in [text1, text2, text3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vendome shooks\n"
     ]
    }
   ],
   "source": [
    "edit_distance(pro[0][0], pro[0][1])\n",
    "print(pro[0][0], pro[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(words, nums):\n",
    "    \n",
    "    # each word has his own cluster\n",
    "    clusters = np.array([i for i in range(len(words))])\n",
    "    acc_nums = len(clusters)\n",
    "    print(clusters)\n",
    "    \n",
    "    def merge_clusters(i,j):\n",
    "        # i is bigger then j\n",
    "        if i < j:\n",
    "            i , j = j, i\n",
    "        for idx in range(len(clusters)):\n",
    "            if clusters[idx] == i:\n",
    "                clusters[idx] = j\n",
    "            elif clusters[idx] > i:\n",
    "                clusters[idx] -= 1\n",
    "                \n",
    "    def find_closest_clusters():\n",
    "        min_ed = 8\n",
    "        candidates =  (0,0)\n",
    "        for w1, w2 in combinations(enumerate(words), 2):            \n",
    "            if clusters[w1[0]] != clusters[w2[0]]:\n",
    "                ed = edit_distance(w1[1], w2[1])            \n",
    "                if ed <= min_ed:                    \n",
    "                    min_ed = ed\n",
    "                    candidates = (clusters[w1[0]], clusters[w2[0]])\n",
    "        return candidates\n",
    "                    \n",
    "            \n",
    "    while acc_nums > nums:\n",
    "        i,j = find_closest_clusters()\n",
    "        merge_clusters(i,j)\n",
    "        acc_nums -= 1\n",
    "        print(clusters)\n",
    "    print(acc_nums)\n",
    "    return clusters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0 1 2 3 2]\n",
      "[0 0 1 2 1]\n",
      "[0 0 1 0 1]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "words = [\"aa\", \"aaa\", \"bartek\", \"ania\", \"barte\"]\n",
    "cl = cluster(words, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = [[],[]]\n",
    "for l in range(2):\n",
    "    for c in range(len(cl)):\n",
    "        if cl[c] == l:\n",
    "            clustered[l].append(words[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aa', 'aaa', 'ania'], ['bartek', 'barte']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(pro[0] + pro[1] + pro[2]))\n",
    "# dont even try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_cluster(words, nums):\n",
    "    clusters = sorted(words)\n",
    "    cl_leng = len(words)//nums\n",
    "    cluster = np.ndarray(len(words), dtype = np.int)\n",
    "    for i in range(nums):\n",
    "        for j in range(i*cl_leng, (i+1)*cl_leng):\n",
    "            cluster[j] = i\n",
    "    if len(words)%nums != 0:\n",
    "        cluster[-(len(words)%nums):] = nums-1\n",
    "    return (clusters, cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ala', 'ania', 'bart', 'bartek', 'tom', 'zbyszek'],\n",
       " array([0, 0, 1, 1, 2, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"ala\", \"tom\", \"bartek\", \"ania\", \"bart\", \"zbyszek\"]\n",
    "naive_cluster(words, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_version(words, nums):\n",
    "    # to pick candidates for most far away points\n",
    "    words_sort = sorted(words, key = lambda x: len(x))\n",
    "    centered = []\n",
    "    for i in range(nums):\n",
    "        centered.append(words_sort[i*len(words)//nums])\n",
    "    clusters = np.zeros(len(words), dtype=np.int)\n",
    "    for i in range(len(words)):\n",
    "        w = words[i]\n",
    "        min_ed = 8\n",
    "        cluster = 0\n",
    "        for c in centered:\n",
    "            ed = edit_distance(w, c)\n",
    "            if ed <= min_ed:\n",
    "                min_ed = ed\n",
    "                clusters[i] = centered.index(c)\n",
    "                cluster = centered.index(c)\n",
    "    return (centered, clusters)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ala', 'ania', 'bartek'], array([0, 0, 2, 1, 2, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"ala\", \"tom\", \"bartek\", \"ania\", \"bart\", \"zbyszek\"]\n",
    "final_version(words, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sizes(clusters):\n",
    "    unique, counts = np.unique(clusters, return_counts=True)\n",
    "    return dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(pro[0] + pro[1] + pro[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = final_version(words, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = final_version(words, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res10 = final_version(words, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3106, 1: 7653}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sizes(res2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1369, 1: 4932, 2: 4458}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sizes(res3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 515,\n",
       " 1: 1123,\n",
       " 2: 960,\n",
       " 3: 883,\n",
       " 4: 2110,\n",
       " 5: 550,\n",
       " 6: 1661,\n",
       " 7: 1324,\n",
       " 8: 691,\n",
       " 9: 942}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sizes(res10[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
