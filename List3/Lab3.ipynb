{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21**\n",
    "\n",
    "For a given bitstring __b__ list all bitstrings **b’**, such that the Hamming distance between `b` and `b’` is equal 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitstring_hamming_distance(b):\n",
    "    n = len(bin(b)) - 2\n",
    "    pattern = 2**(n-1)\n",
    "    while pattern > 0:\n",
    "        print(format(b ^ pattern, f\"0{n}b\"))\n",
    "        pattern = pattern // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00101\n",
      "11101\n",
      "10001\n",
      "10111\n",
      "10100\n"
     ]
    }
   ],
   "source": [
    "bitstring = 0b10101\n",
    "bitstring_hamming_distance(bitstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22**\n",
    "\n",
    "Construct a function that returns a Jaccard similarity for two sets. Beware that this function needs to check if at least one of the sets is nonempty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(s1, s2):\n",
    "    assert s1 or s2 , \"One of the set must contain elements\"\n",
    "    return (len(set(s1) & set(s2)) / len(set(s1) | set(s2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_sim({2,5}, {5,2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**23**\n",
    "\n",
    "Construct a function that computes Jaccard similarity for two strings treated as bags of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def jacc2(s1, s2):\n",
    "    splited1 = [word.lower() for word in s1.split(\" \")]\n",
    "    splited2 = [word.lower() for word in s2.split(\" \")]\n",
    "    freq1 = {i:splited1.count(i) for i in set(splited1)}\n",
    "    freq2 = {i:splited2.count(i) for i in set(splited2)}\n",
    "    inter = 0\n",
    "    for i in set(splited1) & set(splited2):\n",
    "        inter += min(freq1[i], freq2[i])\n",
    "    \n",
    "#     print(inter, set(splited1) & set(splited2))\n",
    "#     print(set(splited1) | set(splited2))\n",
    "    return inter/(len(splited1) + len(splited2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacc2(\"Witam Pana Michała.\", \"Witam PaNa witolda i Pana Michała.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24**\n",
    "\n",
    "(use NLTK) List all words in `text1` with edit distance from the word `dog` smaller than 4. Hint: you can safely reject all long words without computations (why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', ']', '.', '(']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148344"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "l1 = [token for token in list(filter(lambda x: len(x) < 7 and x not in stop_words, text1))\n",
    "         if nltk.edit_distance(token, \"dog\") < 4]\n",
    "l2 = [token for token in list(filter(lambda x: len(x) < 7, text1))\n",
    "         if nltk.edit_distance(token, \"dog\") < 4]\n",
    "print(l1[:5])\n",
    "l2[:5]\n",
    "len(l1)\n",
    "len(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25**\n",
    "\n",
    "(use NLTK) Let `text1-text9` be bags of words. Compute similarity between all pairs of texts.\n",
    "Can't compute jacard distance on baggs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby Dick by Herman Melville 1851 - Sense and Sensibility by Jane Austen 1811: 0.7873816443236149\n",
      "Moby Dick by Herman Melville 1851 - The Book of Genesis: 0.918655312407169\n",
      "Moby Dick by Herman Melville 1851 - Inaugural Address Corpus: 0.7596932621058073\n",
      "Moby Dick by Herman Melville 1851 - Chat Corpus: 0.9021990993748087\n",
      "Moby Dick by Herman Melville 1851 - Monty Python and the Holy Grail: 0.9335110395815521\n",
      "Moby Dick by Herman Melville 1851 - Wall Street Journal: 0.8320154434421057\n",
      "Moby Dick by Herman Melville 1851 - Personals Corpus: 0.9724919916611583\n",
      "Moby Dick by Herman Melville 1851 - The Man Who Was Thursday by G . K . Chesterton 1908: 0.782489869003864\n",
      "Sense and Sensibility by Jane Austen 1811 - The Book of Genesis: 0.8690246257846451\n",
      "Sense and Sensibility by Jane Austen 1811 - Inaugural Address Corpus: 0.7114655716993051\n",
      "Sense and Sensibility by Jane Austen 1811 - Chat Corpus: 0.8689815643458028\n",
      "Sense and Sensibility by Jane Austen 1811 - Monty Python and the Holy Grail: 0.8833908707326429\n",
      "Sense and Sensibility by Jane Austen 1811 - Wall Street Journal: 0.8286454478164322\n",
      "Sense and Sensibility by Jane Austen 1811 - Personals Corpus: 0.9457617879531207\n",
      "Sense and Sensibility by Jane Austen 1811 - The Man Who Was Thursday by G . K . Chesterton 1908: 0.7293468960927845\n",
      "The Book of Genesis - Inaugural Address Corpus: 0.8972541277817659\n",
      "The Book of Genesis - Chat Corpus: 0.9139649299861233\n",
      "The Book of Genesis - Monty Python and the Holy Grail: 0.8754482428878795\n",
      "The Book of Genesis - Wall Street Journal: 0.935235926268593\n",
      "The Book of Genesis - Personals Corpus: 0.9540067720090294\n",
      "The Book of Genesis - The Man Who Was Thursday by G . K . Chesterton 1908: 0.8747891058086286\n",
      "Inaugural Address Corpus - Chat Corpus: 0.8969086783891095\n",
      "Inaugural Address Corpus - Monty Python and the Holy Grail: 0.9118498459239892\n",
      "Inaugural Address Corpus - Wall Street Journal: 0.7770025118615685\n",
      "Inaugural Address Corpus - Personals Corpus: 0.9641294838145232\n",
      "Inaugural Address Corpus - The Man Who Was Thursday by G . K . Chesterton 1908: 0.7698466651559785\n",
      "Chat Corpus - Monty Python and the Holy Grail: 0.8875401144132831\n",
      "Chat Corpus - Wall Street Journal: 0.8991545893719807\n",
      "Chat Corpus - Personals Corpus: 0.9377188975178925\n",
      "Chat Corpus - The Man Who Was Thursday by G . K . Chesterton 1908: 0.8641196612002162\n",
      "Monty Python and the Holy Grail - Wall Street Journal: 0.9341517857142857\n",
      "Monty Python and the Holy Grail - Personals Corpus: 0.9307103064066853\n",
      "Monty Python and the Holy Grail - The Man Who Was Thursday by G . K . Chesterton 1908: 0.8733652725624758\n",
      "Wall Street Journal - Personals Corpus: 0.967222006974041\n",
      "Wall Street Journal - The Man Who Was Thursday by G . K . Chesterton 1908: 0.8426835968500092\n",
      "Personals Corpus - The Man Who Was Thursday by G . K . Chesterton 1908: 0.9505516959542296\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "for t1, t2 in combinations([text1, text2, text3, text4, text5, text6, text7, text8, text9], 2):\n",
    "    print(f\"{t1.name} - {t2.name}: {nltk.jaccard_distance(set(filter(lambda x: x not in stop_words,t1)), set(filter(lambda x: x not in stop_words, t2)))}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**26**\n",
    "\n",
    "(use NLTK) Let us consider a metric space $(S, d)$, where $S$ is the set of words from `text1` and $d$ is the Hamming distance. Find diameter of $(S, d)$.\n",
    "\n",
    "A metric space $M$ is called bounded if there exists some number $r$, such that $d(x,y) ≤ r$ for all $x$ and $y$ in $M$. The smallest possible such $r$ is called the diameter of $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def find_diameter(text):\n",
    "    d = defaultdict(list)\n",
    "    for i in set([t.lower() for t in text]):\n",
    "        d[len(i)].append(i)\n",
    "\n",
    "    d = sorted(d.items(), reverse=True)\n",
    "\n",
    "    r = (0, \"\", \"\")\n",
    "    control = False\n",
    "    for i in range(len(d)):\n",
    "        word_length = d[i][0]\n",
    "        value = d[i][1]\n",
    "        for s1, s2 in combinations(value,2):\n",
    "            dist = sum([ex != ey for ex, ey in zip(s1, s2)])\n",
    "            r = (dist, s1, s2) if dist > r[0] else r\n",
    "        if i+1 < len(d) and r[0] >= d[i+1][0]:\n",
    "            break\n",
    "            \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17, 'superstitiousness', 'cannibalistically'),\n",
       " (16, 'disqualifications', 'companionableness'),\n",
       " (14, 'interpretations', 'zaphnathpaaneah'),\n",
       " (17, 'antiphilosophists', 'misrepresentation'),\n",
       " (31, 'wooooooooooooohoooooooooooooooo', ')))))))))))))))))))))))))))))))')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(find_diameter, [text1, text2, text3, text4, text5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**27**\n",
    "\n",
    "(use NLTK) Construct a dictionary that assigns each pair of consecutive words in `text1` the Jaccard similarity between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('her', 'missing'), 1.0),\n",
       " (('missing', 'children'), 0.8181818181818182),\n",
       " (('found', 'another'), 0.8),\n",
       " (('another', 'orphan'), 0.375),\n",
       " (('orphan', '.'), 1.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zad27 = {(t1,t2):nltk.jaccard_distance(set(t1), set(t2)) for t1, t2 in zip(text1, text1[1:])}\n",
    "list(zad27.items())[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**28**\n",
    "\n",
    "(use NLTK). For two words $v$ and $w$, let `relative edit distance` be the Levensthein distance between $v$ and $w$ divided by the sum of lengths $v$ and $w$. Find two different words in `text2` with minimal relative edit distance.\n",
    "\n",
    "We know that $\\mid   \\mid v \\mid - \\mid w \\mid \\mid \\leqslant L(v, w) \\leqslant \\max\\{\\mid v \\mid, \\mid w \\mid\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_closest(text):\n",
    "    \n",
    "    def relative_edit(a, b):\n",
    "        return nltk.edit_distance(a, b) / (len(a) + len(b))\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    d = defaultdict(set)\n",
    "\n",
    "    for i in text:\n",
    "        if i.lower() not in stop_words:\n",
    "            d[len(i)].add(i.lower())\n",
    "        \n",
    "    d = sorted(d.items(), reverse=True)\n",
    "    \n",
    "    def possibly_min(w1:int, w2:int) -> float:\n",
    "        \"\"\" Return possibly minimall relative edit distance\n",
    "        \"\"\"\n",
    "        return 1/(w1 + w2) if w1 == w2 else abs(w1 - w2)/(w1 + w2)\n",
    "\n",
    "    def checker(index:int, min_i:float) -> int:\n",
    "        \"\"\" Return index from what it is worth to check\n",
    "\n",
    "        We should return index of the elements in list where start to compering\n",
    "        \"\"\"\n",
    "        i = index\n",
    "        if i >= len(d):\n",
    "            return index\n",
    "        for j in range(i+1):\n",
    "            c_min = possibly_min(d[j][0], d[i][0])\n",
    "            if c_min < min_i:\n",
    "                return j\n",
    "        return -1\n",
    "\n",
    "    min_val = 1\n",
    "    min_words = []\n",
    "\n",
    "    for i in range(len(d)):\n",
    "        # get index from what to search\n",
    "        idx = checker(i, min_val)\n",
    "        if idx == -1:\n",
    "            # we can't do better going further\n",
    "            break\n",
    "\n",
    "        for j in range(idx, i+1):\n",
    "            ll = [(relative_edit(w1, w2), w1, w2) for w1 in d[j][1] for w2 in d[i][1] if j != i]\n",
    "            if j == i:\n",
    "                ll = [(relative_edit(w1,w2), w1, w2) for w1, w2 in combinations(d[i][1], 2)]\n",
    "\n",
    "            m_l, w1, w2 = min(\n",
    "                ll,\n",
    "                default=(1, \"\", \"\"), \n",
    "                key=lambda x: x[0]\n",
    "            )\n",
    "            if m_l < min_val:\n",
    "                min_val = m_l\n",
    "                min_words = [(w1, w2) for v, w1, w2 in ll if v == m_l]\n",
    "            elif m_l == min_val:\n",
    "                min_words.extend([(w1, w2) for v, w1, w2 in ll if v == m_l])\n",
    "\n",
    "\n",
    "    return (min_val, min_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.030303030303030304, [('circumnavigations', 'circumnavigation')])\n",
      "(0.034482758620689655, [('representations', 'representation'), ('acknowledgments', 'acknowledgment'), ('disappointments', 'disappointment')])\n",
      "(0.034482758620689655, [('interpretations', 'interpretation')])\n",
      "(0.034482758620689655, [('recommendations', 'recommendation'), ('administrations', 'administration'), ('congratulations', 'congratulation'), ('representations', 'representation'), ('accomplishments', 'accomplishment'), ('representatives', 'representative'), ('discriminations', 'discrimination')])\n",
      "(0.01818181818181818, [('!!!!!!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!!!!!')])\n",
      "(0.045454545454545456, [('syndicalist', 'syndicalism')])\n",
      "(0.034482758620689655, [('recommendations', 'recommendation'), ('administrations', 'administration'), ('fundamentalists', 'fundamentalist'), ('forest-products', 'forest-product'), ('pharmaceuticals', 'pharmaceutical'), ('representatives', 'representative'), ('microprocessors', 'microprocessor'), ('superconductors', 'superconductor')])\n",
      "(0.047619047619047616, [('appreciated', 'appreciate')])\n",
      "(0.03571428571428571, [('unquestionable', 'unquestionably')])\n"
     ]
    }
   ],
   "source": [
    "for tup in list(map(lambda x: find_closest(x),[text1, text2, text3, text4, text5, text6, text7, text8, text9])):\n",
    "    print(tup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# d = defaultdict(set)\n",
    "\n",
    "# def relative_edit(a, b):\n",
    "#     return nltk.edit_distance(a, b) / (len(a) + len(b))\n",
    "\n",
    "# for i in text2:\n",
    "#     if i.lower() not in stop_words:\n",
    "#         d[len(i)].add(i.lower())\n",
    "        \n",
    "# d = sorted(d.items(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034482758620689655 [('representations', 'representation'), ('acknowledgments', 'acknowledgment'), ('disappointments', 'disappointment')]\n"
     ]
    }
   ],
   "source": [
    "# print(d[0])\n",
    "# print(d[1])\n",
    "# print(d[2])\n",
    "# print(d[3])\n",
    "\n",
    "def possibly_min(w1:int, w2:int) -> float:\n",
    "    \"\"\" Return possibly minimall relative edit distance\n",
    "    \"\"\"\n",
    "    return 1/(w1 + w2) if w1 == w2 else abs(w1 - w2)/(w1 + w2)\n",
    "\n",
    "def checker(index:int, min_i:float) -> int:\n",
    "    \"\"\" Return index from what it is worth to check\n",
    "    \n",
    "    We should return index of the elements in list where start to compering\n",
    "    \"\"\"\n",
    "    i = index\n",
    "    if i >= len(d):\n",
    "        return index\n",
    "    for j in range(i+1):\n",
    "        c_min = possibly_min(d[j][0], d[i][0])\n",
    "        if c_min < min_i:\n",
    "            return j\n",
    "    return -1\n",
    "    \n",
    "min_val = 1\n",
    "min_words = []\n",
    "\n",
    "for i in range(len(d)):\n",
    "    # get index from what to search\n",
    "    idx = checker(i, min_val)\n",
    "    if idx == -1:\n",
    "        # we can't do better going further\n",
    "        break\n",
    "        \n",
    "    for j in range(idx, i+1):\n",
    "        ll = [(relative_edit(w1, w2), w1, w2) for w1 in d[j][1] for w2 in d[i][1] if j != i]\n",
    "        if j == i:\n",
    "            ll = [(relative_edit(w1,w2), w1, w2) for w1, w2 in combinations(d[i][1], 2)]\n",
    "    \n",
    "        m_l, w1, w2 = min(\n",
    "            ll,\n",
    "            default=(1, \"\", \"\"), \n",
    "            key=lambda x: x[0]\n",
    "        )\n",
    "        if m_l < min_val:\n",
    "            min_val = m_l\n",
    "            min_words = [(w1, w2) for v, w1, w2 in ll if v == m_l]\n",
    "        elif m_l == min_val:\n",
    "            min_words.extend([(w1, w2) for v, w1, w2 in ll if v == m_l])\n",
    "    \n",
    "\n",
    "print(min_val, min_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 Cleveland owned\n",
      "0.38095238095238093 Cleveland deliberating\n",
      "0.35294117647058826 Cleveland released\n",
      "0.3333333333333333 Cleveland lovely\n",
      "0.29411764705882354 Cleveland revealed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2665it [00:00, 11793.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2777777777777778 Cleveland Abbeyland\n",
      "0.2222222222222222 Cleveland Courtland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5554it [00:00, 13011.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18181818181818182 owned opened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7359it [00:00, 14176.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666 owned crowned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9615it [00:00, 15929.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1111111111111111 owned owed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11747it [00:00, 17206.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 owned owner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25233it [00:01, 25292.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333 deliberating deliberation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51942it [00:02, 20504.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06666666666666667 released release\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72044it [00:03, 20411.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037037037037037035 qualification qualifications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5074614it [04:23, 21561.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034482758620689655 disappointments disappointment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22434951it [19:24, 19273.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034482758620689655 disappointments disappointment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.034482758620689655, 'disappointments', 'disappointment')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = set(filter(lambda x: x not in stop_words, text2))\n",
    "\n",
    "def bad():\n",
    "    m = 1\n",
    "    s1, s2 = \"\", \"\"\n",
    "    for d1, d2 in tqdm(combinations(t2, 2)):\n",
    "        v = relative_edit(d1, d2)\n",
    "        if v < m:\n",
    "            print(v, d1, d2)\n",
    "            m = v\n",
    "            s1, s2 = d1, d2\n",
    "    print(m,s1,s2)\n",
    "    return (m, s1, s2)\n",
    "    \n",
    "def min_rel():\n",
    "    for i1, i2 in combinations(d, 2):\n",
    "        print(i1, i2)\n",
    "        break\n",
    "        for s1, s2 in combinations(d, 2):\n",
    "            dist = relative_edit(s1, s2)\n",
    "            yield s1, s2, dist\n",
    "            \n",
    "bad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**29**\n",
    "\n",
    "For a given bitstring **b** and a natural number *r* list all bitstrings __b’__, such that theHamming distance between `b` and `b’` is equal _n_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Return an enumerate object.\n",
       "\n",
       "  iterable\n",
       "    an object supporting iteration\n",
       "\n",
       "The enumerate object yields pairs containing a count (from start, which\n",
       "defaults to zero) and a value yielded by the iterable argument.\n",
       "\n",
       "enumerate is useful for obtaining an indexed list:\n",
       "    (0, seq[0]), (1, seq[1]), (2, seq[2]), ...\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enumerate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def hamming_distance2(b, r):\n",
    "    for c in combinations(enumerate(b), r):\n",
    "        for i in range(len(b)):\n",
    "            if i in [j[0] for j in c]:\n",
    "                print((int(b[i]) + 1) % 2, end= '')\n",
    "            else:\n",
    "                print(b[i], end = '')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00001\n"
     ]
    }
   ],
   "source": [
    "hamming_distance2(\"00001\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**30**\n",
    "\n",
    "Construct a function that for a given string and a natural number _k_ returns a **set** of all its *k*-shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_shingles(s, k):\n",
    "    r = set()\n",
    "    for i in range(0, len(s)):\n",
    "        if i+k <= len(s):\n",
    "            r.add(s[i:i+k])\n",
    "        else:\n",
    "            break\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dendw', 'edend', 'endwa', 'jeden'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_shingles(\"jedendwa\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
